{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to BioEPIC Skills","text":"<p>A Python library designed to simplify various research tasks for users looking to extract and prepare structured data from scientific literature for use with the EcoSIM model.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\udd0d API Search: Flexible search and query capabilities</li> <li>\ud83d\udd10 Authentication: Secure API authentication handling</li> <li>\ud83d\udcca Data Processing: Utilities for data transformation and analysis</li> <li>\ud83e\uddea Testing: Comprehensive test suite</li> <li>\ud83d\udcda Documentation: Complete API reference and user guides</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation Guide</li> <li>Quick Start Tutorial</li> <li>API Reference</li> <li>Contributing Guidelines</li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>BioEPIC Skills provides a collection of general-purpose functions that facilitate easy access, manipulation, and analysis of biological data through APIs.</p>"},{"location":"#key-components","title":"Key Components","text":"<ul> <li>APIBase: Base class for API interactions with environment configuration</li> <li>APISearch: Search and retrieve data from API collections</li> <li>BioEPICAuth: Authentication handler with token management</li> <li>DataProcessing: Data transformation and analysis utilities</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Install from source:</p> <pre><code>git clone https://github.com/bioepic-data/bioepic_skills.git\ncd bioepic_skills\npip install -e \".[dev]\"\n</code></pre> <p>Or via pip (once published):</p> <pre><code>pip install bioepic_skills\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from bioepic_skills.api_search import APISearch\nfrom bioepic_skills.data_processing import DataProcessing\n\n# Create clients\napi_client = APISearch(collection_name=\"samples\")\ndp = DataProcessing()\n\n# Get records\nrecords = api_client.get_records(max_page_size=10)\n\n# Convert to DataFrame\ndf = dp.convert_to_df(records)\nprint(df.head())\n</code></pre>"},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 Check the User Guide for detailed information</li> <li>\ud83d\udc1b Report issues on GitHub</li> <li>\ud83d\udcac Ask questions in Discussions</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the BSD License. See the LICENSE file for details.</p>"},{"location":"api/api-base/","title":"API Base","text":""},{"location":"api/api-base/#bioepic_skills.api_base.APIBase","title":"APIBase","text":"<p>Base class for interacting with the BioEPIC API. Sets the base URL for the API based on the environment. Environment is defaulted to the production instance of the API. This functionality is in place for testing different environments.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <p>The environment to use. Default is prod. Must be one of the following:     prod     dev</p> <code>'prod'</code> Source code in <code>bioepic_skills/api_base.py</code> <pre><code>class APIBase:\n    \"\"\"\n    Base class for interacting with the BioEPIC API. Sets the base URL for the API based on the environment.\n    Environment is defaulted to the production instance of the API. This functionality is in place for testing different environments.\n\n    Parameters\n    ----------\n    env: str\n        The environment to use. Default is prod. Must be one of the following:\n            prod\n            dev\n\n    \"\"\"\n\n    def __init__(self, env=\"prod\"):\n        if env == \"prod\":\n            self.base_url = \"https://api.bioepic.example.com\"  # Update with actual URL\n        elif env == \"dev\":\n            self.base_url = \"https://api-dev.bioepic.example.com\"  # Update with actual URL\n        else:\n            raise ValueError(\"env must be one of the following: prod, dev\")\n</code></pre>"},{"location":"api/api-search/","title":"API Search","text":""},{"location":"api/api-search/#bioepic_skills.api_search.APISearch","title":"APISearch","text":"<p>               Bases: <code>APIBase</code></p> <p>Class to interact with the BioEPIC API to get collections of data.</p> Source code in <code>bioepic_skills/api_search.py</code> <pre><code>class APISearch(APIBase):\n    \"\"\"\n    Class to interact with the BioEPIC API to get collections of data.\n    \"\"\"\n\n    def __init__(self, collection_name=None, env=\"prod\"):\n        super().__init__(env=env)\n        self.collection_name = collection_name\n\n    def get_records(\n        self,\n        filter: str = \"\",\n        max_page_size: int = 100,\n        fields: str = \"\",\n        all_pages: bool = False,\n    ) -&gt; list[dict]:\n        \"\"\"\n        Get a collection of data from the API.\n\n        Parameters\n        ----------\n        filter: str\n            The filter to apply to the query. Default is an empty string.\n        max_page_size: int\n            The maximum number of items to return per page. Default is 100.\n        fields: str\n            The fields to return. Default is all fields.\n        all_pages: bool\n            True to return all pages. False to return the first page. Default is False.\n\n        Returns\n        -------\n        list[dict]\n            A list of records.\n\n        Raises\n        ------\n        RuntimeError\n            If the API request fails.\n\n        \"\"\"\n        logging.debug(f\"get_records Filter: {filter}\")\n        filter = urllib.parse.quote(filter)\n        logging.debug(f\"get_records encoded Filter: {filter}\")\n\n        url = f\"{self.base_url}/api/{self.collection_name}?filter={filter}&amp;max_page_size={max_page_size}&amp;projection={fields}\"\n\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            logger.error(\"API request failed\", exc_info=True)\n            raise RuntimeError(\"Failed to get collection from BioEPIC API\") from e\n        else:\n            logging.debug(\n                f\"API request response: {response.json()}\\n API Status Code: {response.status_code}\"\n            )\n\n        if all_pages:\n            return self._get_all_pages(response, filter, max_page_size, fields)\n        else:\n            return response.json().get(\"results\", [])\n\n    def _get_all_pages(\n        self,\n        response: requests.models.Response,\n        filter: str = \"\",\n        max_page_size: int = 100,\n        fields: str = \"\",\n    ):\n        \"\"\"\n        Get all pages of results from the API.\n\n        Parameters\n        ----------\n        response: requests.models.Response\n            The initial response from the API.\n        filter: str\n            The filter to apply to the query.\n        max_page_size: int\n            The maximum number of items to return per page.\n        fields: str\n            The fields to return.\n\n        Returns\n        -------\n        list[dict]\n            A list of all records from all pages.\n        \"\"\"\n        results = response.json()\n\n        while True:\n            if response.json().get(\"next_page_token\"):\n                next_page_token = response.json()[\"next_page_token\"]\n            else:\n                break\n\n            url = f\"{self.base_url}/api/{self.collection_name}?filter={filter}&amp;max_page_size={max_page_size}&amp;projection={fields}&amp;page_token={next_page_token}\"\n\n            try:\n                response = requests.get(url)\n                response.raise_for_status()\n            except requests.exceptions.RequestException as e:\n                logger.error(\"API request failed\", exc_info=True)\n                raise RuntimeError(\"Failed to get collection from BioEPIC API\") from e\n            else:\n                logging.debug(\n                    f\"API request response: {response.json()}\\n API Status Code: {response.status_code}\"\n                )\n                results[\"results\"].extend(response.json()[\"results\"])\n\n        return results.get(\"results\", [])\n\n    def get_record_by_id(self, record_id: str) -&gt; dict:\n        \"\"\"\n        Get a record by its ID.\n\n        Parameters\n        ----------\n        record_id: str\n            The ID of the record to retrieve.\n\n        Returns\n        -------\n        dict\n            The record data.\n\n        Raises\n        ------\n        RuntimeError\n            If the API request fails.\n        \"\"\"\n        url = f\"{self.base_url}/api/{self.collection_name}/{record_id}\"\n\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            logger.error(\"API request failed\", exc_info=True)\n            raise RuntimeError(f\"Failed to get record {record_id} from BioEPIC API\") from e\n\n        return response.json()\n\n    def get_record_by_filter(\n        self, filter: str, max_page_size=25, fields: str = \"\", all_pages=False\n    ) -&gt; list[dict]:\n        \"\"\"\n        Get records by a filter.\n\n        Parameters\n        ----------\n        filter: str\n            The filter to apply to the query.\n        max_page_size: int\n            The maximum number of items to return per page. Default is 25.\n        fields: str\n            The fields to return. Default is all fields.\n        all_pages: bool\n            True to return all pages. False to return the first page. Default is False.\n\n        Returns\n        -------\n        list[dict]\n            A list of records matching the filter.\n        \"\"\"\n        return self.get_records(filter, max_page_size, fields, all_pages)\n\n    def get_record_by_attribute(\n        self,\n        attribute_name: str,\n        attribute_value: str,\n        max_page_size: int = 25,\n        fields: str = \"\",\n        all_pages: bool = False,\n        exact_match: bool = False,\n    ) -&gt; list[dict]:\n        \"\"\"\n        Get records by a specific attribute value.\n\n        Parameters\n        ----------\n        attribute_name: str\n            The name of the attribute to filter by.\n        attribute_value: str\n            The value of the attribute to filter by.\n        max_page_size: int\n            The maximum number of items to return per page. Default is 25.\n        fields: str\n            The fields to return. Default is all fields.\n        all_pages: bool\n            True to return all pages. False to return the first page. Default is False.\n        exact_match: bool\n            If True, performs an exact match. If False, performs a regex match. Default is False.\n\n        Returns\n        -------\n        list[dict]\n            A list of records matching the attribute criteria.\n        \"\"\"\n        from bioepic_skills.data_processing import DataProcessing\n\n        dp = DataProcessing()\n        filter_dict = dp.build_filter({attribute_name: attribute_value}, exact_match=exact_match)\n\n        return self.get_records(filter_dict, max_page_size, fields, all_pages)\n</code></pre>"},{"location":"api/api-search/#bioepic_skills.api_search.APISearch.get_records","title":"get_records","text":"<pre><code>get_records(\n    filter: str = \"\",\n    max_page_size: int = 100,\n    fields: str = \"\",\n    all_pages: bool = False,\n) -&gt; list[dict]\n</code></pre> <p>Get a collection of data from the API.</p> <p>Parameters:</p> Name Type Description Default <code>filter</code> <code>str</code> <p>The filter to apply to the query. Default is an empty string.</p> <code>''</code> <code>max_page_size</code> <code>int</code> <p>The maximum number of items to return per page. Default is 100.</p> <code>100</code> <code>fields</code> <code>str</code> <p>The fields to return. Default is all fields.</p> <code>''</code> <code>all_pages</code> <code>bool</code> <p>True to return all pages. False to return the first page. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>A list of records.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the API request fails.</p> Source code in <code>bioepic_skills/api_search.py</code> <pre><code>def get_records(\n    self,\n    filter: str = \"\",\n    max_page_size: int = 100,\n    fields: str = \"\",\n    all_pages: bool = False,\n) -&gt; list[dict]:\n    \"\"\"\n    Get a collection of data from the API.\n\n    Parameters\n    ----------\n    filter: str\n        The filter to apply to the query. Default is an empty string.\n    max_page_size: int\n        The maximum number of items to return per page. Default is 100.\n    fields: str\n        The fields to return. Default is all fields.\n    all_pages: bool\n        True to return all pages. False to return the first page. Default is False.\n\n    Returns\n    -------\n    list[dict]\n        A list of records.\n\n    Raises\n    ------\n    RuntimeError\n        If the API request fails.\n\n    \"\"\"\n    logging.debug(f\"get_records Filter: {filter}\")\n    filter = urllib.parse.quote(filter)\n    logging.debug(f\"get_records encoded Filter: {filter}\")\n\n    url = f\"{self.base_url}/api/{self.collection_name}?filter={filter}&amp;max_page_size={max_page_size}&amp;projection={fields}\"\n\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        logger.error(\"API request failed\", exc_info=True)\n        raise RuntimeError(\"Failed to get collection from BioEPIC API\") from e\n    else:\n        logging.debug(\n            f\"API request response: {response.json()}\\n API Status Code: {response.status_code}\"\n        )\n\n    if all_pages:\n        return self._get_all_pages(response, filter, max_page_size, fields)\n    else:\n        return response.json().get(\"results\", [])\n</code></pre>"},{"location":"api/api-search/#bioepic_skills.api_search.APISearch.get_record_by_id","title":"get_record_by_id","text":"<pre><code>get_record_by_id(record_id: str) -&gt; dict\n</code></pre> <p>Get a record by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>record_id</code> <code>str</code> <p>The ID of the record to retrieve.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The record data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the API request fails.</p> Source code in <code>bioepic_skills/api_search.py</code> <pre><code>def get_record_by_id(self, record_id: str) -&gt; dict:\n    \"\"\"\n    Get a record by its ID.\n\n    Parameters\n    ----------\n    record_id: str\n        The ID of the record to retrieve.\n\n    Returns\n    -------\n    dict\n        The record data.\n\n    Raises\n    ------\n    RuntimeError\n        If the API request fails.\n    \"\"\"\n    url = f\"{self.base_url}/api/{self.collection_name}/{record_id}\"\n\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        logger.error(\"API request failed\", exc_info=True)\n        raise RuntimeError(f\"Failed to get record {record_id} from BioEPIC API\") from e\n\n    return response.json()\n</code></pre>"},{"location":"api/api-search/#bioepic_skills.api_search.APISearch.get_record_by_filter","title":"get_record_by_filter","text":"<pre><code>get_record_by_filter(\n    filter: str,\n    max_page_size=25,\n    fields: str = \"\",\n    all_pages=False,\n) -&gt; list[dict]\n</code></pre> <p>Get records by a filter.</p> <p>Parameters:</p> Name Type Description Default <code>filter</code> <code>str</code> <p>The filter to apply to the query.</p> required <code>max_page_size</code> <p>The maximum number of items to return per page. Default is 25.</p> <code>25</code> <code>fields</code> <code>str</code> <p>The fields to return. Default is all fields.</p> <code>''</code> <code>all_pages</code> <p>True to return all pages. False to return the first page. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>A list of records matching the filter.</p> Source code in <code>bioepic_skills/api_search.py</code> <pre><code>def get_record_by_filter(\n    self, filter: str, max_page_size=25, fields: str = \"\", all_pages=False\n) -&gt; list[dict]:\n    \"\"\"\n    Get records by a filter.\n\n    Parameters\n    ----------\n    filter: str\n        The filter to apply to the query.\n    max_page_size: int\n        The maximum number of items to return per page. Default is 25.\n    fields: str\n        The fields to return. Default is all fields.\n    all_pages: bool\n        True to return all pages. False to return the first page. Default is False.\n\n    Returns\n    -------\n    list[dict]\n        A list of records matching the filter.\n    \"\"\"\n    return self.get_records(filter, max_page_size, fields, all_pages)\n</code></pre>"},{"location":"api/api-search/#bioepic_skills.api_search.APISearch.get_record_by_attribute","title":"get_record_by_attribute","text":"<pre><code>get_record_by_attribute(\n    attribute_name: str,\n    attribute_value: str,\n    max_page_size: int = 25,\n    fields: str = \"\",\n    all_pages: bool = False,\n    exact_match: bool = False,\n) -&gt; list[dict]\n</code></pre> <p>Get records by a specific attribute value.</p> <p>Parameters:</p> Name Type Description Default <code>attribute_name</code> <code>str</code> <p>The name of the attribute to filter by.</p> required <code>attribute_value</code> <code>str</code> <p>The value of the attribute to filter by.</p> required <code>max_page_size</code> <code>int</code> <p>The maximum number of items to return per page. Default is 25.</p> <code>25</code> <code>fields</code> <code>str</code> <p>The fields to return. Default is all fields.</p> <code>''</code> <code>all_pages</code> <code>bool</code> <p>True to return all pages. False to return the first page. Default is False.</p> <code>False</code> <code>exact_match</code> <code>bool</code> <p>If True, performs an exact match. If False, performs a regex match. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>A list of records matching the attribute criteria.</p> Source code in <code>bioepic_skills/api_search.py</code> <pre><code>def get_record_by_attribute(\n    self,\n    attribute_name: str,\n    attribute_value: str,\n    max_page_size: int = 25,\n    fields: str = \"\",\n    all_pages: bool = False,\n    exact_match: bool = False,\n) -&gt; list[dict]:\n    \"\"\"\n    Get records by a specific attribute value.\n\n    Parameters\n    ----------\n    attribute_name: str\n        The name of the attribute to filter by.\n    attribute_value: str\n        The value of the attribute to filter by.\n    max_page_size: int\n        The maximum number of items to return per page. Default is 25.\n    fields: str\n        The fields to return. Default is all fields.\n    all_pages: bool\n        True to return all pages. False to return the first page. Default is False.\n    exact_match: bool\n        If True, performs an exact match. If False, performs a regex match. Default is False.\n\n    Returns\n    -------\n    list[dict]\n        A list of records matching the attribute criteria.\n    \"\"\"\n    from bioepic_skills.data_processing import DataProcessing\n\n    dp = DataProcessing()\n    filter_dict = dp.build_filter({attribute_name: attribute_value}, exact_match=exact_match)\n\n    return self.get_records(filter_dict, max_page_size, fields, all_pages)\n</code></pre>"},{"location":"api/auth/","title":"Authentication","text":""},{"location":"api/auth/#bioepicauth","title":"BioEPICAuth","text":""},{"location":"api/auth/#bioepic_skills.auth.BioEPICAuth","title":"BioEPICAuth","text":"<p>               Bases: <code>APIBase</code></p> <p>Authentication handler for BioEPIC API operations.</p> <p>You must provide either:   - client_id and client_secret (for client credentials grant), OR   - username and password (for password grant).</p> <p>Parameters:</p> Name Type Description Default <code>client_id</code> <code>str</code> <p>The client ID for BioEPIC API authentication (required if using client credentials grant).</p> <code>None</code> <code>client_secret</code> <code>str</code> <p>The client secret for BioEPIC API authentication (required if using client credentials grant).</p> <code>None</code> <code>username</code> <code>str</code> <p>The username for BioEPIC API authentication (required if using password grant).</p> <code>None</code> <code>password</code> <code>str</code> <p>The password for BioEPIC API authentication (required if using password grant).</p> <code>None</code> Notes <p>Security Warning: Your client_id and client_secret should be stored in a secure location.     We recommend using environment variables.     Do not hard code these values in your code.</p> Source code in <code>bioepic_skills/auth.py</code> <pre><code>class BioEPICAuth(APIBase):\n    \"\"\"\n    Authentication handler for BioEPIC API operations.\n\n    You must provide either:\n      - client_id and client_secret (for client credentials grant), OR\n      - username and password (for password grant).\n\n    Parameters\n    ----------\n    client_id : str\n        The client ID for BioEPIC API authentication (required if using client credentials grant).\n    client_secret : str\n        The client secret for BioEPIC API authentication (required if using client credentials grant).\n    username : str\n        The username for BioEPIC API authentication (required if using password grant).\n    password : str\n        The password for BioEPIC API authentication (required if using password grant).\n\n    Notes\n    -----\n    Security Warning: Your client_id and client_secret should be stored in a secure location.\n        We recommend using environment variables.\n        Do not hard code these values in your code.\n    \"\"\"\n\n    def __init__(\n        self,\n        client_id: str | None = None,\n        client_secret: str | None = None,\n        username: str | None = None,\n        password: str | None = None,\n        env: str = \"prod\",\n    ):\n        super().__init__(env=env)\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.username = username\n        self.password = password\n        self.token = None\n        self.token_expiry = None\n\n    def has_credentials(self) -&gt; bool:\n        \"\"\"Check if the credentials are passed in properly.\"\"\"\n        has_client_creds = self.client_id is not None and self.client_secret is not None\n        has_user_creds = self.username is not None and self.password is not None\n        return has_client_creds or has_user_creds\n\n    def get_token(self) -&gt; str:\n        \"\"\"Get a valid access token, refreshing if necessary.\"\"\"\n        if self.token and self._is_token_valid():\n            return self.token\n        return self._refresh_token()\n\n    def _is_token_valid(self) -&gt; bool:\n        \"\"\"Check if current token is valid and not expired.\"\"\"\n        if not self.token or not self.token_expiry:\n            return False\n        # Add a 5-minute buffer before expiry\n        return datetime.now() &lt; (self.token_expiry - timedelta(minutes=5))\n\n    def _refresh_token(self) -&gt; str:\n        \"\"\"Refresh the access token.\"\"\"\n        url = f\"{self.base_url}/token\"\n\n        if self.client_id and self.client_secret:\n            # Client credentials grant\n            data = {\n                \"grant_type\": \"client_credentials\",\n                \"client_id\": self.client_id,\n                \"client_secret\": self.client_secret,\n            }\n        elif self.username and self.password:\n            # Password grant\n            data = {\n                \"grant_type\": \"password\",\n                \"username\": self.username,\n                \"password\": self.password,\n            }\n        else:\n            raise ValueError(\"No valid credentials provided\")\n\n        try:\n            response = requests.post(url, data=data)\n            response.raise_for_status()\n            token_data = response.json()\n            self.token = token_data[\"access_token\"]\n            # Assuming token includes expires_in field in seconds\n            expires_in = token_data.get(\"expires_in\", 3600)\n            self.token_expiry = datetime.now() + timedelta(seconds=expires_in)\n            logging.debug(\"Token refreshed successfully\")\n            return self.token\n        except requests.exceptions.RequestException as e:\n            logger.error(\"Failed to refresh token\", exc_info=True)\n            raise RuntimeError(\"Failed to authenticate with BioEPIC API\") from e\n</code></pre>"},{"location":"api/auth/#bioepic_skills.auth.BioEPICAuth.has_credentials","title":"has_credentials","text":"<pre><code>has_credentials() -&gt; bool\n</code></pre> <p>Check if the credentials are passed in properly.</p> Source code in <code>bioepic_skills/auth.py</code> <pre><code>def has_credentials(self) -&gt; bool:\n    \"\"\"Check if the credentials are passed in properly.\"\"\"\n    has_client_creds = self.client_id is not None and self.client_secret is not None\n    has_user_creds = self.username is not None and self.password is not None\n    return has_client_creds or has_user_creds\n</code></pre>"},{"location":"api/auth/#bioepic_skills.auth.BioEPICAuth.get_token","title":"get_token","text":"<pre><code>get_token() -&gt; str\n</code></pre> <p>Get a valid access token, refreshing if necessary.</p> Source code in <code>bioepic_skills/auth.py</code> <pre><code>def get_token(self) -&gt; str:\n    \"\"\"Get a valid access token, refreshing if necessary.\"\"\"\n    if self.token and self._is_token_valid():\n        return self.token\n    return self._refresh_token()\n</code></pre>"},{"location":"api/auth/#decorators","title":"Decorators","text":""},{"location":"api/auth/#requires_auth","title":"requires_auth","text":""},{"location":"api/auth/#bioepic_skills.decorators.requires_auth","title":"requires_auth","text":"<pre><code>requires_auth(f)\n</code></pre> <p>Decorator for methods that need authentication</p> Source code in <code>bioepic_skills/decorators.py</code> <pre><code>def requires_auth(f):\n    \"\"\"Decorator for methods that need authentication\"\"\"\n\n    @wraps(f)\n    def wrapper(self, *args, **kwargs):\n        # Get function parameter names (excluding 'self')\n        import inspect\n\n        sig = inspect.signature(f)\n        param_names = list(sig.parameters.keys())[1:]  # Skip 'self'\n\n        # Create a dictionary of all arguments (positional + keyword)\n        bound_args = {}\n        for i, arg in enumerate(args):\n            if i &lt; len(param_names):\n                bound_args[param_names[i]] = arg\n        bound_args.update(kwargs)\n\n        # Check if client_id and client_secret are provided\n        client_id = bound_args.get(\"client_id\")\n        client_secret = bound_args.get(\"client_secret\")\n\n        # If credentials provided in function call, proceed\n        if client_id is not None and client_secret is not None:\n            return f(self, *args, **kwargs)\n\n        if not self.auth.has_credentials():\n            raise AuthenticationError(\n                f\"{f.__name__} requires authentication. Either provide `client_id` and `client_secret` OR `username` and `password`.\"\n            )\n        return f(self, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/auth/#authenticationerror","title":"AuthenticationError","text":""},{"location":"api/auth/#bioepic_skills.decorators.AuthenticationError","title":"AuthenticationError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for authentication failures.</p> Source code in <code>bioepic_skills/decorators.py</code> <pre><code>class AuthenticationError(Exception):\n    \"\"\"Custom exception for authentication failures.\"\"\"\n    pass\n</code></pre>"},{"location":"api/data-processing/","title":"Data Processing","text":""},{"location":"api/data-processing/#bioepic_skills.data_processing.DataProcessing","title":"DataProcessing","text":"Source code in <code>bioepic_skills/data_processing.py</code> <pre><code>class DataProcessing:\n    def __init__(self):\n        pass\n\n    def _string_mongo_list(self, data: list) -&gt; str:\n        \"\"\"\n        Convert elements in a list to use double quotes instead of single quotes.\n        This is required for mongo queries.\n\n        Parameters\n        ----------\n        data: list\n            A list of dictionaries.\n\n        Returns\n        -------\n        str\n            A string representation of the list with double quotes.\n        \"\"\"\n        return str(data).replace(\"'\", '\"')\n\n    def convert_to_df(self, data: list) -&gt; pd.DataFrame:\n        \"\"\"\n        Convert a list of dictionaries to a pandas dataframe.\n\n        Parameters\n        ----------\n        data: list\n            A list of dictionaries.\n\n        Returns\n        -------\n        pd.DataFrame\n            A pandas dataframe.\n        \"\"\"\n        return pd.DataFrame(data)\n\n    def split_list(self, input_list: list, chunk_size: int = 100) -&gt; list:\n        \"\"\"\n        Split a list into chunks of a specified size.\n\n        Parameters\n        ----------\n        input_list: list\n            The list to split.\n        chunk_size: int\n            The size of each chunk. Default is 100.\n\n        Returns\n        -------\n        list\n            A list of lists, where each inner list is a chunk of the original list.\n        \"\"\"\n        return [\n            input_list[i : i + chunk_size]\n            for i in range(0, len(input_list), chunk_size)\n        ]\n\n    def rename_columns(self, df: pd.DataFrame, new_col_names: list) -&gt; pd.DataFrame:\n        \"\"\"\n        Rename columns in a pandas dataframe.\n\n        Parameters\n        ----------\n        df: pd.DataFrame\n            The pandas dataframe to rename columns.\n        new_col_names: list\n            A list of new column names. Names MUST be in order of the columns in the dataframe.\n            Example:\n                If the current column names are - ['old_col1', 'old_col2', 'old_col3']\n                You will need to pass in the new names like - ['new_col1', 'new_col2', 'new_col3']\n\n        Returns\n        -------\n        pd.DataFrame\n            A pandas dataframe with renamed columns.\n\n        \"\"\"\n        df.columns = new_col_names\n        return df\n\n    def merge_dataframes(\n        self, column: str, df1: pd.DataFrame, df2: pd.DataFrame\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Merge two dataframes.\n\n        Parameters\n        ----------\n        column: str\n            The column to merge on.\n        df1: pd.DataFrame\n            The first dataframe to merge.\n        df2: pd.DataFrame\n            The second dataframe to merge.\n\n        Returns\n        -------\n        pd.DataFrame\n            A pandas dataframe with the merged data.\n        \"\"\"\n        return pd.merge(df1, df2, on=column, how=\"inner\")\n\n    def merge_df(\n        self,\n        df1: pd.DataFrame,\n        df2: pd.DataFrame,\n        key1: str,\n        key2: str,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Define a merging function to join results\n        This function merges new results with the previous results that were used for the new API request. \n        It uses two keys from each result to match on.\n\n        Parameters\n        ----------\n        df1: pd.DataFrame\n            The first dataframe to merge.\n        df2: pd.DataFrame\n            The second dataframe to merge.\n        key1: str\n            The key in df1 to match with key2 in df2.\n        key2: str\n            The key in df2 to match with key1 in df1.\n\n        Returns\n        -------\n        pd.DataFrame\n            A pandas dataframe with the merged data.\n        \"\"\"\n\n        def identify_and_explode(df):\n            for col in df.columns:\n                if any(isinstance(item, list) for item in df[col]):\n                    df = df.explode(col)\n            return df\n\n        df1 = identify_and_explode(df1)\n        df2 = identify_and_explode(df2)\n\n        # Merge dataframes\n        merged_df = pd.merge(df1, df2, left_on=key1, right_on=key2)\n        # Drop any duplicated rows\n        merged_df.drop_duplicates(keep=\"first\", inplace=True)\n        return merged_df\n\n    def build_filter(self, attributes: dict, exact_match: bool = False) -&gt; dict:\n        \"\"\"\n        Create a MongoDB filter using $regex for each attribute in the input dictionary. \n        For nested attributes, use dot notation.\n\n        Parameters\n        ----------\n        attributes: dict\n            Dictionary of attribute names and their corresponding values to match using regex.\n            Example: {\"name\": \"example\", \"description\": \"example\", \"geo_loc_name\": \"example\"}\n        exact_match: bool\n            This var is used to determine if the inputted attribute value is an exact match or a partial match. \n            Default is False, meaning the user does not need to input an exact match.\n            Under the hood this is used to determine if the inputted attribute value should be wrapped in a regex expression.\n\n        Returns\n        -------\n        dict\n            A dictionary representing the MongoDB filter.\n            Example: {\"name\": {\"$regex\": \"example\", \"$options\": \"i\"}, \"description\": {\"$regex\": \"example\", \"$options\": \"i\"}}\n        \"\"\"\n        filter_dict = {}\n        if exact_match:\n            for attribute_name, attribute_value in attributes.items():\n                filter_dict[attribute_name] = attribute_value\n        else:\n            for attribute_name, attribute_value in attributes.items():\n                # escape special characters - mongo db filters require special characters to be double escaped\n                escaped_value = re.sub(r\"([\\W])\", r\"\\\\\\1\", attribute_value)\n                logging.debug(f\"Escaped value: {escaped_value}\")\n                logging.debug(f\"Attribute name: {attribute_name}\")\n                filter_dict[attribute_name] = {\"$regex\": escaped_value, \"$options\": \"i\"}\n                logging.debug(f\"Filter dict: {filter_dict}\")\n        clean = self._string_mongo_list(filter_dict)\n        logging.debug(f\"Filter cleaned: {clean}\")\n        return clean\n\n    def extract_field(self, api_results: list, field_name: str) -&gt; list:\n        \"\"\"\n        Extract a specific field from a list of API results.\n\n        Parameters\n        ----------\n        api_results: list\n            A list of dictionaries representing API results.\n        field_name: str\n            The name of the field to extract.\n\n        Returns\n        -------\n        list\n            A list of values for the specified field.\n        \"\"\"\n        return [result.get(field_name) for result in api_results if field_name in result]\n</code></pre>"},{"location":"api/data-processing/#bioepic_skills.data_processing.DataProcessing.convert_to_df","title":"convert_to_df","text":"<pre><code>convert_to_df(data: list) -&gt; pd.DataFrame\n</code></pre> <p>Convert a list of dictionaries to a pandas dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>A list of dictionaries.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe.</p> Source code in <code>bioepic_skills/data_processing.py</code> <pre><code>def convert_to_df(self, data: list) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert a list of dictionaries to a pandas dataframe.\n\n    Parameters\n    ----------\n    data: list\n        A list of dictionaries.\n\n    Returns\n    -------\n    pd.DataFrame\n        A pandas dataframe.\n    \"\"\"\n    return pd.DataFrame(data)\n</code></pre>"},{"location":"api/data-processing/#bioepic_skills.data_processing.DataProcessing.split_list","title":"split_list","text":"<pre><code>split_list(input_list: list, chunk_size: int = 100) -&gt; list\n</code></pre> <p>Split a list into chunks of a specified size.</p> <p>Parameters:</p> Name Type Description Default <code>input_list</code> <code>list</code> <p>The list to split.</p> required <code>chunk_size</code> <code>int</code> <p>The size of each chunk. Default is 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>list</code> <p>A list of lists, where each inner list is a chunk of the original list.</p> Source code in <code>bioepic_skills/data_processing.py</code> <pre><code>def split_list(self, input_list: list, chunk_size: int = 100) -&gt; list:\n    \"\"\"\n    Split a list into chunks of a specified size.\n\n    Parameters\n    ----------\n    input_list: list\n        The list to split.\n    chunk_size: int\n        The size of each chunk. Default is 100.\n\n    Returns\n    -------\n    list\n        A list of lists, where each inner list is a chunk of the original list.\n    \"\"\"\n    return [\n        input_list[i : i + chunk_size]\n        for i in range(0, len(input_list), chunk_size)\n    ]\n</code></pre>"},{"location":"api/data-processing/#bioepic_skills.data_processing.DataProcessing.rename_columns","title":"rename_columns","text":"<pre><code>rename_columns(\n    df: DataFrame, new_col_names: list\n) -&gt; pd.DataFrame\n</code></pre> <p>Rename columns in a pandas dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The pandas dataframe to rename columns.</p> required <code>new_col_names</code> <code>list</code> <p>A list of new column names. Names MUST be in order of the columns in the dataframe. Example:     If the current column names are - ['old_col1', 'old_col2', 'old_col3']     You will need to pass in the new names like - ['new_col1', 'new_col2', 'new_col3']</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe with renamed columns.</p> Source code in <code>bioepic_skills/data_processing.py</code> <pre><code>def rename_columns(self, df: pd.DataFrame, new_col_names: list) -&gt; pd.DataFrame:\n    \"\"\"\n    Rename columns in a pandas dataframe.\n\n    Parameters\n    ----------\n    df: pd.DataFrame\n        The pandas dataframe to rename columns.\n    new_col_names: list\n        A list of new column names. Names MUST be in order of the columns in the dataframe.\n        Example:\n            If the current column names are - ['old_col1', 'old_col2', 'old_col3']\n            You will need to pass in the new names like - ['new_col1', 'new_col2', 'new_col3']\n\n    Returns\n    -------\n    pd.DataFrame\n        A pandas dataframe with renamed columns.\n\n    \"\"\"\n    df.columns = new_col_names\n    return df\n</code></pre>"},{"location":"api/data-processing/#bioepic_skills.data_processing.DataProcessing.merge_dataframes","title":"merge_dataframes","text":"<pre><code>merge_dataframes(\n    column: str, df1: DataFrame, df2: DataFrame\n) -&gt; pd.DataFrame\n</code></pre> <p>Merge two dataframes.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>The column to merge on.</p> required <code>df1</code> <code>DataFrame</code> <p>The first dataframe to merge.</p> required <code>df2</code> <code>DataFrame</code> <p>The second dataframe to merge.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe with the merged data.</p> Source code in <code>bioepic_skills/data_processing.py</code> <pre><code>def merge_dataframes(\n    self, column: str, df1: pd.DataFrame, df2: pd.DataFrame\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Merge two dataframes.\n\n    Parameters\n    ----------\n    column: str\n        The column to merge on.\n    df1: pd.DataFrame\n        The first dataframe to merge.\n    df2: pd.DataFrame\n        The second dataframe to merge.\n\n    Returns\n    -------\n    pd.DataFrame\n        A pandas dataframe with the merged data.\n    \"\"\"\n    return pd.merge(df1, df2, on=column, how=\"inner\")\n</code></pre>"},{"location":"api/data-processing/#bioepic_skills.data_processing.DataProcessing.merge_df","title":"merge_df","text":"<pre><code>merge_df(\n    df1: DataFrame, df2: DataFrame, key1: str, key2: str\n) -&gt; pd.DataFrame\n</code></pre> <p>Define a merging function to join results This function merges new results with the previous results that were used for the new API request.  It uses two keys from each result to match on.</p> <p>Parameters:</p> Name Type Description Default <code>df1</code> <code>DataFrame</code> <p>The first dataframe to merge.</p> required <code>df2</code> <code>DataFrame</code> <p>The second dataframe to merge.</p> required <code>key1</code> <code>str</code> <p>The key in df1 to match with key2 in df2.</p> required <code>key2</code> <code>str</code> <p>The key in df2 to match with key1 in df1.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas dataframe with the merged data.</p> Source code in <code>bioepic_skills/data_processing.py</code> <pre><code>def merge_df(\n    self,\n    df1: pd.DataFrame,\n    df2: pd.DataFrame,\n    key1: str,\n    key2: str,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Define a merging function to join results\n    This function merges new results with the previous results that were used for the new API request. \n    It uses two keys from each result to match on.\n\n    Parameters\n    ----------\n    df1: pd.DataFrame\n        The first dataframe to merge.\n    df2: pd.DataFrame\n        The second dataframe to merge.\n    key1: str\n        The key in df1 to match with key2 in df2.\n    key2: str\n        The key in df2 to match with key1 in df1.\n\n    Returns\n    -------\n    pd.DataFrame\n        A pandas dataframe with the merged data.\n    \"\"\"\n\n    def identify_and_explode(df):\n        for col in df.columns:\n            if any(isinstance(item, list) for item in df[col]):\n                df = df.explode(col)\n        return df\n\n    df1 = identify_and_explode(df1)\n    df2 = identify_and_explode(df2)\n\n    # Merge dataframes\n    merged_df = pd.merge(df1, df2, left_on=key1, right_on=key2)\n    # Drop any duplicated rows\n    merged_df.drop_duplicates(keep=\"first\", inplace=True)\n    return merged_df\n</code></pre>"},{"location":"api/data-processing/#bioepic_skills.data_processing.DataProcessing.build_filter","title":"build_filter","text":"<pre><code>build_filter(\n    attributes: dict, exact_match: bool = False\n) -&gt; dict\n</code></pre> <p>Create a MongoDB filter using $regex for each attribute in the input dictionary.  For nested attributes, use dot notation.</p> <p>Parameters:</p> Name Type Description Default <code>attributes</code> <code>dict</code> <p>Dictionary of attribute names and their corresponding values to match using regex. Example: {\"name\": \"example\", \"description\": \"example\", \"geo_loc_name\": \"example\"}</p> required <code>exact_match</code> <code>bool</code> <p>This var is used to determine if the inputted attribute value is an exact match or a partial match.  Default is False, meaning the user does not need to input an exact match. Under the hood this is used to determine if the inputted attribute value should be wrapped in a regex expression.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary representing the MongoDB filter. Example: {\"name\": {\"$regex\": \"example\", \"$options\": \"i\"}, \"description\": {\"$regex\": \"example\", \"$options\": \"i\"}}</p> Source code in <code>bioepic_skills/data_processing.py</code> <pre><code>def build_filter(self, attributes: dict, exact_match: bool = False) -&gt; dict:\n    \"\"\"\n    Create a MongoDB filter using $regex for each attribute in the input dictionary. \n    For nested attributes, use dot notation.\n\n    Parameters\n    ----------\n    attributes: dict\n        Dictionary of attribute names and their corresponding values to match using regex.\n        Example: {\"name\": \"example\", \"description\": \"example\", \"geo_loc_name\": \"example\"}\n    exact_match: bool\n        This var is used to determine if the inputted attribute value is an exact match or a partial match. \n        Default is False, meaning the user does not need to input an exact match.\n        Under the hood this is used to determine if the inputted attribute value should be wrapped in a regex expression.\n\n    Returns\n    -------\n    dict\n        A dictionary representing the MongoDB filter.\n        Example: {\"name\": {\"$regex\": \"example\", \"$options\": \"i\"}, \"description\": {\"$regex\": \"example\", \"$options\": \"i\"}}\n    \"\"\"\n    filter_dict = {}\n    if exact_match:\n        for attribute_name, attribute_value in attributes.items():\n            filter_dict[attribute_name] = attribute_value\n    else:\n        for attribute_name, attribute_value in attributes.items():\n            # escape special characters - mongo db filters require special characters to be double escaped\n            escaped_value = re.sub(r\"([\\W])\", r\"\\\\\\1\", attribute_value)\n            logging.debug(f\"Escaped value: {escaped_value}\")\n            logging.debug(f\"Attribute name: {attribute_name}\")\n            filter_dict[attribute_name] = {\"$regex\": escaped_value, \"$options\": \"i\"}\n            logging.debug(f\"Filter dict: {filter_dict}\")\n    clean = self._string_mongo_list(filter_dict)\n    logging.debug(f\"Filter cleaned: {clean}\")\n    return clean\n</code></pre>"},{"location":"api/data-processing/#bioepic_skills.data_processing.DataProcessing.extract_field","title":"extract_field","text":"<pre><code>extract_field(api_results: list, field_name: str) -&gt; list\n</code></pre> <p>Extract a specific field from a list of API results.</p> <p>Parameters:</p> Name Type Description Default <code>api_results</code> <code>list</code> <p>A list of dictionaries representing API results.</p> required <code>field_name</code> <code>str</code> <p>The name of the field to extract.</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of values for the specified field.</p> Source code in <code>bioepic_skills/data_processing.py</code> <pre><code>def extract_field(self, api_results: list, field_name: str) -&gt; list:\n    \"\"\"\n    Extract a specific field from a list of API results.\n\n    Parameters\n    ----------\n    api_results: list\n        A list of dictionaries representing API results.\n    field_name: str\n        The name of the field to extract.\n\n    Returns\n    -------\n    list\n        A list of values for the specified field.\n    \"\"\"\n    return [result.get(field_name) for result in api_results if field_name in result]\n</code></pre>"},{"location":"api/utils/","title":"Utilities","text":""},{"location":"api/utils/#bioepic_skills.utils.Utils","title":"Utils","text":"Source code in <code>bioepic_skills/utils.py</code> <pre><code>class Utils:\n    def __init__(self):\n        pass\n</code></pre>"},{"location":"development/changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"development/changelog/#unreleased","title":"Unreleased","text":""},{"location":"development/changelog/#changed","title":"Changed","text":"<ul> <li>Migrated documentation from Sphinx to MkDocs with Material theme</li> <li>Updated documentation structure for better organization</li> <li>Switched from pip to uv for package management</li> <li>Changed build backend from setuptools to hatchling</li> <li>Removed requirements.txt files (now managed by pyproject.toml)</li> <li>Updated CI/CD workflows to use uv</li> <li>Added ruff as a linting tool</li> </ul>"},{"location":"development/changelog/#010-2025-11-10","title":"0.1.0 - 2025-11-10","text":""},{"location":"development/changelog/#added","title":"Added","text":"<ul> <li>Initial project structure</li> <li>Base API functionality (<code>APIBase</code>, <code>APISearch</code>)</li> <li>Authentication system (<code>BioEPICAuth</code>)</li> <li>Data processing utilities (<code>DataProcessing</code>)</li> <li>Custom decorators (<code>@requires_auth</code>)</li> <li>Basic test suite</li> <li>Documentation setup</li> <li>Example usage code</li> <li>GitHub Actions CI/CD workflow</li> <li>Contributing guidelines</li> <li>Project metadata and configuration</li> </ul>"},{"location":"development/changelog/#documentation","title":"Documentation","text":"<ul> <li>Installation guide</li> <li>Quick start tutorial</li> <li>User guide with authentication and data processing examples</li> <li>API reference for all modules</li> <li>Development documentation</li> </ul>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to BioEPIC Skills!</p>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":""},{"location":"development/contributing/#using-uv-recommended","title":"Using uv (Recommended)","text":"<ol> <li> <p>Install uv: <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></p> </li> <li> <p>Clone the repository: <pre><code>git clone https://github.com/bioepic-data/bioepic_skills.git\ncd bioepic_skills\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>uv sync\n</code></pre></p> </li> <li> <p>Set up environment variables: <pre><code>cp .env.example .env\n# Edit .env with your credentials\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#using-pip","title":"Using pip","text":"<ol> <li> <p>Clone the repository: <pre><code>git clone https://github.com/bioepic-data/bioepic_skills.git\ncd bioepic_skills\n</code></pre></p> </li> <li> <p>Create a virtual environment: <pre><code>python3 -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>pip install -e \".[dev]\"\n</code></pre></p> </li> <li> <p>Set up environment variables: <pre><code>cp .env.example .env\n# Edit .env with your credentials\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#running-tests","title":"Running Tests","text":"<p>Run all tests: <pre><code>uv run pytest\n</code></pre></p> <p>Run with coverage: <pre><code>uv run pytest --cov=bioepic_skills --cov-report=html\n</code></pre></p> <p>Run specific test files: <pre><code>uv run pytest bioepic_skills/test/test_api_search.py\nuv run pytest bioepic_skills/test/test_data_processing.py\n</code></pre></p>"},{"location":"development/contributing/#building-documentation","title":"Building Documentation","text":"<p>Build the documentation locally: <pre><code>uv run mkdocs serve\n</code></pre></p> <p>This will start a local development server at <code>http://127.0.0.1:8000/</code> where you can preview your changes.</p> <p>To build the static site: <pre><code>uv run mkdocs build\n</code></pre></p> <p>The documentation will be built in the <code>site/</code> directory.</p>"},{"location":"development/contributing/#project-structure","title":"Project Structure","text":"<pre><code>bioepic_skills/\n\u251c\u2500\u2500 bioepic_skills/          # Main package directory\n\u2502   \u251c\u2500\u2500 __init__.py          # Package initialization\n\u2502   \u251c\u2500\u2500 api_base.py          # Base API class\n\u2502   \u251c\u2500\u2500 api_search.py        # API search functionality\n\u2502   \u251c\u2500\u2500 auth.py              # Authentication handler\n\u2502   \u251c\u2500\u2500 data_processing.py   # Data processing utilities\n\u2502   \u251c\u2500\u2500 decorators.py        # Custom decorators\n\u2502   \u251c\u2500\u2500 utils.py             # Utility functions\n\u2502   \u251c\u2500\u2500 example_usage.py     # Usage examples\n\u2502   \u2514\u2500\u2500 test/                # Test directory\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 test_api_search.py\n\u2502       \u2514\u2500\u2500 test_data_processing.py\n\u251c\u2500\u2500 docs/                    # Documentation (MkDocs)\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 user-guide/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u2514\u2500\u2500 development/\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 ci.yml           # GitHub Actions CI/CD\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .env.example\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 mkdocs.yml               # MkDocs configuration\n\u251c\u2500\u2500 CONTRIBUTING.md\n\u2514\u2500\u2500 CHANGELOG.md\n</code></pre>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<p>We follow Python best practices:</p> <ul> <li>Use meaningful variable and function names</li> <li>Add docstrings to all public functions and classes</li> <li>Follow PEP 8 style guidelines</li> <li>Keep functions focused and modular</li> <li>Add type hints where appropriate</li> </ul> <p>Example:</p> <pre><code>def get_record_by_id(self, record_id: str) -&gt; dict:\n    \"\"\"\n    Retrieve a single record by its ID.\n\n    Parameters\n    ----------\n    record_id : str\n        The unique identifier of the record\n\n    Returns\n    -------\n    dict\n        The record data\n\n    Raises\n    ------\n    RuntimeError\n        If the API request fails\n    \"\"\"\n    # Implementation...\n</code></pre>"},{"location":"development/contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch:    <pre><code>git checkout -b feature/amazing-feature\n</code></pre></li> <li>Make your changes</li> <li>Run tests to ensure everything works:    <pre><code>pytest\n</code></pre></li> <li>Commit your changes:    <pre><code>git commit -m 'Add some amazing feature'\n</code></pre></li> <li>Push to your fork:    <pre><code>git push origin feature/amazing-feature\n</code></pre></li> <li>Open a Pull Request</li> </ol>"},{"location":"development/contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Provide a clear description of the changes</li> <li>Reference any related issues</li> <li>Ensure all tests pass</li> <li>Update documentation if needed</li> <li>Add tests for new features</li> <li>Keep changes focused - one feature per PR</li> </ul>"},{"location":"development/contributing/#reporting-issues","title":"Reporting Issues","text":"<p>When reporting issues, please include:</p> <ul> <li>Python version</li> <li>Operating system</li> <li>Steps to reproduce the issue</li> <li>Expected behavior</li> <li>Actual behavior</li> <li>Error messages or stack traces</li> </ul>"},{"location":"development/contributing/#documentation","title":"Documentation","text":"<p>When adding or modifying features:</p> <ol> <li>Update relevant documentation in <code>docs/</code></li> <li>Add docstrings to new functions/classes</li> <li>Update the CHANGELOG.md</li> <li>Test your documentation locally with <code>mkdocs serve</code></li> </ol>"},{"location":"development/contributing/#questions","title":"Questions?","text":"<p>Feel free to open an issue for:</p> <ul> <li>Feature requests</li> <li>Bug reports</li> <li>Documentation improvements</li> <li>General questions</li> </ul>"},{"location":"development/contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the same license as the project (see LICENSE file).</p>"},{"location":"development/testing/","title":"Testing","text":"<p>BioEPIC Skills uses pytest for testing.</p>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":""},{"location":"development/testing/#run-all-tests","title":"Run All Tests","text":"<pre><code>uv run pytest\n</code></pre>"},{"location":"development/testing/#run-with-coverage","title":"Run with Coverage","text":"<pre><code>uv run pytest --cov=bioepic_skills --cov-report=html\n</code></pre> <p>View the coverage report: <pre><code>open htmlcov/index.html  # macOS\nxdg-open htmlcov/index.html  # Linux\n</code></pre></p>"},{"location":"development/testing/#run-specific-tests","title":"Run Specific Tests","text":"<p>Run a specific test file: <pre><code>uv run pytest bioepic_skills/test/test_api_search.py\n</code></pre></p> <p>Run a specific test class: <pre><code>uv run pytest bioepic_skills/test/test_api_search.py::TestAPISearch\n</code></pre></p> <p>Run a specific test method: <pre><code>uv run pytest bioepic_skills/test/test_api_search.py::TestAPISearch::test_get_records\n</code></pre></p>"},{"location":"development/testing/#verbose-output","title":"Verbose Output","text":"<pre><code>uv run pytest -v\n</code></pre>"},{"location":"development/testing/#stop-on-first-failure","title":"Stop on First Failure","text":"<pre><code>uv run pytest -x\n</code></pre>"},{"location":"development/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<p>Tests are located in <code>bioepic_skills/test/</code>:</p> <pre><code>bioepic_skills/test/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 test_api_search.py\n\u2514\u2500\u2500 test_data_processing.py\n</code></pre>"},{"location":"development/testing/#example-test","title":"Example Test","text":"<pre><code>import pytest\nfrom bioepic_skills.api_search import APISearch\n\nclass TestAPISearch:\n    def setup_method(self):\n        \"\"\"Set up test fixtures\"\"\"\n        self.api = APISearch(collection_name=\"test\")\n\n    def test_initialization(self):\n        \"\"\"Test API client initialization\"\"\"\n        assert self.api.collection_name == \"test\"\n        assert self.api.base_url is not None\n\n    def test_get_records(self):\n        \"\"\"Test getting records\"\"\"\n        records = self.api.get_records(max_page_size=10)\n        assert isinstance(records, list)\n        assert len(records) &lt;= 10\n</code></pre>"},{"location":"development/testing/#using-fixtures","title":"Using Fixtures","text":"<pre><code>import pytest\nfrom bioepic_skills.api_search import APISearch\n\n@pytest.fixture\ndef api_client():\n    \"\"\"Create an API client for testing\"\"\"\n    return APISearch(collection_name=\"test\")\n\ndef test_with_fixture(api_client):\n    \"\"\"Test using a fixture\"\"\"\n    records = api_client.get_records(max_page_size=5)\n    assert isinstance(records, list)\n</code></pre>"},{"location":"development/testing/#mocking-api-calls","title":"Mocking API Calls","text":"<pre><code>from unittest.mock import Mock, patch\n\ndef test_api_with_mock():\n    \"\"\"Test with mocked API response\"\"\"\n    with patch('requests.get') as mock_get:\n        # Set up mock response\n        mock_response = Mock()\n        mock_response.json.return_value = {\n            \"data\": [{\"id\": \"1\", \"name\": \"Test\"}]\n        }\n        mock_response.status_code = 200\n        mock_get.return_value = mock_response\n\n        # Test your code\n        api = APISearch(collection_name=\"test\")\n        records = api.get_records()\n\n        # Assertions\n        assert len(records) == 1\n        assert records[0][\"id\"] == \"1\"\n</code></pre>"},{"location":"development/testing/#testing-exceptions","title":"Testing Exceptions","text":"<pre><code>import pytest\n\ndef test_error_handling():\n    \"\"\"Test that proper errors are raised\"\"\"\n    api = APISearch(collection_name=\"test\")\n\n    with pytest.raises(RuntimeError):\n        api.get_record_by_id(None)\n</code></pre>"},{"location":"development/testing/#test-coverage","title":"Test Coverage","text":""},{"location":"development/testing/#view-coverage","title":"View Coverage","text":"<p>After running tests with coverage: <pre><code>pytest --cov=bioepic_skills --cov-report=term\n</code></pre></p>"},{"location":"development/testing/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Aim for &gt;80% code coverage</li> <li>Focus on critical functionality</li> <li>Don't obsess over 100% - quality over quantity</li> </ul>"},{"location":"development/testing/#exclude-from-coverage","title":"Exclude from Coverage","text":"<p>To exclude code from coverage, use <code># pragma: no cover</code>:</p> <pre><code>def debug_function():  # pragma: no cover\n    \"\"\"This function is only for debugging\"\"\"\n    print(\"Debug info\")\n</code></pre>"},{"location":"development/testing/#continuous-integration","title":"Continuous Integration","text":"<p>Tests run automatically on: - Every push to GitHub - Every pull request - Python versions: 3.10, 3.11, 3.12</p> <p>See <code>.github/workflows/ci.yml</code> for CI configuration.</p>"},{"location":"development/testing/#best-practices","title":"Best Practices","text":""},{"location":"development/testing/#1-test-naming","title":"1. Test Naming","text":"<p>Use descriptive test names:</p> <pre><code># Good\ndef test_get_records_returns_list():\n    pass\n\ndef test_get_records_respects_max_page_size():\n    pass\n\n# Avoid\ndef test_1():\n    pass\n\ndef test_records():\n    pass\n</code></pre>"},{"location":"development/testing/#2-arrange-act-assert","title":"2. Arrange-Act-Assert","text":"<p>Structure tests with AAA pattern:</p> <pre><code>def test_merge_dataframes():\n    # Arrange\n    df1 = pd.DataFrame({\"id\": [1, 2], \"name\": [\"A\", \"B\"]})\n    df2 = pd.DataFrame({\"id\": [1, 2], \"value\": [10, 20]})\n    dp = DataProcessing()\n\n    # Act\n    result = dp.merge_dataframes(\"id\", df1, df2)\n\n    # Assert\n    assert len(result) == 2\n    assert \"name\" in result.columns\n    assert \"value\" in result.columns\n</code></pre>"},{"location":"development/testing/#3-test-one-thing","title":"3. Test One Thing","text":"<p>Each test should verify one behavior:</p> <pre><code># Good\ndef test_convert_to_df_returns_dataframe():\n    dp = DataProcessing()\n    records = [{\"id\": \"1\"}]\n    df = dp.convert_to_df(records)\n    assert isinstance(df, pd.DataFrame)\n\ndef test_convert_to_df_has_correct_columns():\n    dp = DataProcessing()\n    records = [{\"id\": \"1\", \"name\": \"Test\"}]\n    df = dp.convert_to_df(records)\n    assert list(df.columns) == [\"id\", \"name\"]\n\n# Avoid testing multiple things in one test\n</code></pre>"},{"location":"development/testing/#4-use-descriptive-assertions","title":"4. Use Descriptive Assertions","text":"<pre><code># Good\nassert len(records) == 5, \"Expected 5 records\"\nassert record[\"type\"] == \"sample\", \"Record type should be 'sample'\"\n\n# Also good\nassert len(records) == 5\nassert record[\"type\"] == \"sample\"\n</code></pre>"},{"location":"development/testing/#5-clean-up-resources","title":"5. Clean Up Resources","text":"<pre><code>class TestWithResources:\n    def setup_method(self):\n        \"\"\"Set up before each test\"\"\"\n        self.temp_file = \"test.txt\"\n        with open(self.temp_file, \"w\") as f:\n            f.write(\"test data\")\n\n    def teardown_method(self):\n        \"\"\"Clean up after each test\"\"\"\n        if os.path.exists(self.temp_file):\n            os.remove(self.temp_file)\n\n    def test_something(self):\n        # Test uses self.temp_file\n        pass\n</code></pre>"},{"location":"development/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"development/testing/#run-with-print-statements","title":"Run with Print Statements","text":"<pre><code>uv run pytest -s  # Shows print output\n</code></pre>"},{"location":"development/testing/#use-pdb-debugger","title":"Use pdb Debugger","text":"<pre><code>def test_debug():\n    import pdb; pdb.set_trace()\n    # Test code...\n</code></pre>"},{"location":"development/testing/#show-locals-on-failure","title":"Show Locals on Failure","text":"<pre><code>uv run pytest -l  # Show local variables on failure\n</code></pre>"},{"location":"development/testing/#common-testing-patterns","title":"Common Testing Patterns","text":""},{"location":"development/testing/#testing-data-processing","title":"Testing Data Processing","text":"<pre><code>def test_data_transformation():\n    dp = DataProcessing()\n    input_data = [{\"id\": \"1\", \"value\": \"10\"}]\n\n    df = dp.convert_to_df(input_data)\n\n    assert df[\"id\"][0] == \"1\"\n    assert df[\"value\"][0] == \"10\"\n</code></pre>"},{"location":"development/testing/#testing-api-calls","title":"Testing API Calls","text":"<pre><code>@pytest.mark.integration\ndef test_real_api_call():\n    \"\"\"Integration test with real API\"\"\"\n    api = APISearch(collection_name=\"samples\")\n    records = api.get_records(max_page_size=1)\n\n    assert len(records) &gt; 0\n    assert \"id\" in records[0]\n</code></pre>"},{"location":"development/testing/#testing-authentication","title":"Testing Authentication","text":"<pre><code>def test_authentication():\n    auth = BioEPICAuth(\n        client_id=\"test_id\",\n        client_secret=\"test_secret\"\n    )\n\n    assert auth.has_credentials()\n</code></pre>"},{"location":"development/testing/#next-steps","title":"Next Steps","text":"<ul> <li>Review existing tests in <code>bioepic_skills/test/</code></li> <li>Add tests when contributing new features</li> <li>Run tests before submitting pull requests</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10 or higher</li> <li>uv (recommended) or pip</li> </ul>"},{"location":"getting-started/installation/#using-uv-recommended","title":"Using uv (Recommended)","text":"<p>uv is a fast Python package installer and resolver. It's significantly faster than pip and provides better dependency resolution.</p>"},{"location":"getting-started/installation/#install-uv","title":"Install uv","text":"<pre><code># macOS and Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre>"},{"location":"getting-started/installation/#install-bioepic-skills","title":"Install BioEPIC Skills","text":"<pre><code># Clone the repository\ngit clone https://github.com/bioepic-data/bioepic_skills.git\ncd bioepic_skills\n\n# Install with all dependencies\nuv sync\n\n# Or install without dev dependencies\nuv sync --no-dev\n</code></pre>"},{"location":"getting-started/installation/#using-pip","title":"Using pip","text":"<p>For traditional pip installation:</p> <pre><code># From source\ngit clone https://github.com/bioepic-data/bioepic_skills.git\ncd bioepic_skills\npip install -e \".[dev]\"\n\n# Or once published to PyPI\npip install bioepic_skills\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Verify the installation by checking the version:</p> <pre><code>import bioepic_skills\nprint(bioepic_skills.__version__)\n</code></pre>"},{"location":"getting-started/installation/#virtual-environments","title":"Virtual Environments","text":"<p>uv automatically manages virtual environments for you. When you run <code>uv sync</code>, it creates a <code>.venv</code> directory in your project.</p> <p>To activate the virtual environment manually:</p> <pre><code># Unix/macOS\nsource .venv/bin/activate\n\n# Windows\n.venv\\Scripts\\activate\n</code></pre> <p>However, with uv, you typically don't need to activate the environment - just use <code>uv run</code> to execute commands:</p> <pre><code>uv run python script.py\nuv run pytest\nuv run mkdocs serve\n</code></pre>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":""},{"location":"getting-started/installation/#core-dependencies","title":"Core Dependencies","text":"<p>The following packages are installed automatically:</p> <ul> <li><code>pandas</code> (\u22652.2.3) - Data manipulation and analysis</li> <li><code>requests</code> (\u22652.32.3) - HTTP library for API calls</li> <li><code>matplotlib</code> (\u22653.10.0) - Plotting library</li> </ul>"},{"location":"getting-started/installation/#development-dependencies","title":"Development Dependencies","text":"<p>For development work, additional packages are installed:</p> <ul> <li><code>pytest</code> (\u22657.0.0) - Testing framework</li> <li><code>pytest-cov</code> (\u22654.0.0) - Coverage plugin for pytest</li> <li><code>python-dotenv</code> (\u22651.0.0) - Environment variable management</li> <li><code>mkdocs</code> (\u22651.5.0) - Documentation generator</li> <li><code>mkdocs-material</code> (\u22659.0.0) - Material theme for MkDocs</li> <li><code>mkdocstrings[python]</code> (\u22650.24.0) - Python documentation plugin</li> <li><code>ruff</code> (\u22650.1.0) - Fast Python linter</li> </ul> <p>These are automatically installed when you run <code>uv sync</code>.</p>"},{"location":"getting-started/installation/#working-with-uv","title":"Working with uv","text":""},{"location":"getting-started/installation/#common-commands","title":"Common Commands","text":"<pre><code># Install/sync dependencies\nuv sync\n\n# Add a new dependency\nuv add package-name\n\n# Add a dev dependency\nuv add --dev package-name\n\n# Remove a dependency\nuv remove package-name\n\n# Run a command in the virtual environment\nuv run python script.py\nuv run pytest\n\n# Update dependencies\nuv lock --upgrade\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>After installation, proceed to the Quick Start Guide to learn how to use the library.</p>"},{"location":"getting-started/quickstart/","title":"Quick Start Guide","text":"<p>This guide will help you get started with BioEPIC Skills quickly.</p>"},{"location":"getting-started/quickstart/#setup","title":"Setup","text":""},{"location":"getting-started/quickstart/#1-install-the-package","title":"1. Install the Package","text":"<pre><code>pip install bioepic_skills\n</code></pre>"},{"location":"getting-started/quickstart/#2-configure-environment-variables","title":"2. Configure Environment Variables","text":"<p>Create a <code>.env</code> file in your project directory:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> with your credentials:</p> <pre><code>ENV=prod\nCLIENT_ID=your_client_id_here\nCLIENT_SECRET=your_client_secret_here\n</code></pre>"},{"location":"getting-started/quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/quickstart/#simple-api-query","title":"Simple API Query","text":"<pre><code>from bioepic_skills.api_search import APISearch\nfrom bioepic_skills.data_processing import DataProcessing\n\n# Create clients\napi_client = APISearch(collection_name=\"samples\")\ndp = DataProcessing()\n\n# Get records\nrecords = api_client.get_records(max_page_size=10)\nprint(f\"Retrieved {len(records)} records\")\n\n# Convert to DataFrame\ndf = dp.convert_to_df(records)\nprint(df.head())\n</code></pre>"},{"location":"getting-started/quickstart/#search-by-attribute","title":"Search by Attribute","text":"<pre><code># Search for specific records\nresults = api_client.get_record_by_attribute(\n    attribute_name=\"type\",\n    attribute_value=\"biological_sample\",\n    max_page_size=50,\n    all_pages=True\n)\n\nprint(f\"Found {len(results)} matching records\")\n</code></pre>"},{"location":"getting-started/quickstart/#get-record-by-id","title":"Get Record by ID","text":"<pre><code># Retrieve a specific record\nrecord = api_client.get_record_by_id(\"sample-12345\")\nprint(record)\n</code></pre>"},{"location":"getting-started/quickstart/#using-authentication","title":"Using Authentication","text":"<p>For endpoints that require authentication:</p> <pre><code>from bioepic_skills.auth import BioEPICAuth\nfrom bioepic_skills.api_search import APISearch\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n# Initialize authentication\nauth = BioEPICAuth(\n    client_id=os.getenv(\"CLIENT_ID\"),\n    client_secret=os.getenv(\"CLIENT_SECRET\")\n)\n\n# Verify credentials\nif auth.has_credentials():\n    print(\"Authentication configured successfully\")\n\n    # Get token\n    token = auth.get_token()\n    print(\"Token acquired\")\n</code></pre>"},{"location":"getting-started/quickstart/#data-processing-examples","title":"Data Processing Examples","text":""},{"location":"getting-started/quickstart/#extract-specific-fields","title":"Extract Specific Fields","text":"<pre><code>from bioepic_skills.data_processing import DataProcessing\n\ndp = DataProcessing()\n\n# Extract IDs from records\nids = dp.extract_field(records, \"id\")\nprint(f\"Extracted {len(ids)} IDs\")\n</code></pre>"},{"location":"getting-started/quickstart/#build-custom-filters","title":"Build Custom Filters","text":"<pre><code># Build a MongoDB-style filter\nfilter_query = dp.build_filter(\n    {\"name\": \"test\", \"status\": \"active\"},\n    exact_match=False\n)\n\n# Use the filter in a query\nfiltered_records = api_client.get_record_by_filter(filter_query)\n</code></pre>"},{"location":"getting-started/quickstart/#merge-dataframes","title":"Merge DataFrames","text":"<pre><code># Merge two DataFrames on a common column\nmerged_df = dp.merge_dataframes(\"id\", df1, df2)\nprint(f\"Merged dataframe shape: {merged_df.shape}\")\n</code></pre>"},{"location":"getting-started/quickstart/#split-lists-into-chunks","title":"Split Lists into Chunks","text":"<pre><code># Split a large list into smaller chunks\nlarge_list = list(range(250))\nchunks = dp.split_list(large_list, chunk_size=100)\nprint(f\"Split into {len(chunks)} chunks\")\n</code></pre>"},{"location":"getting-started/quickstart/#debugging","title":"Debugging","text":"<p>Enable debug logging to see detailed information:</p> <pre><code>import logging\n\nlogging.basicConfig(level=logging.DEBUG)\n\n# Now run your code - you'll see detailed debug output\napi_client = APISearch(collection_name=\"samples\")\nrecords = api_client.get_records(max_page_size=5)\n</code></pre>"},{"location":"getting-started/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"getting-started/quickstart/#pagination-get-all-pages","title":"Pagination - Get All Pages","text":"<pre><code># Get all pages of results\nall_records = api_client.get_records(\n    max_page_size=100,\n    all_pages=True\n)\nprint(f\"Retrieved {len(all_records)} total records\")\n</code></pre>"},{"location":"getting-started/quickstart/#filter-and-export","title":"Filter and Export","text":"<pre><code># Filter, convert to DataFrame, and export\nresults = api_client.get_record_by_attribute(\n    attribute_name=\"category\",\n    attribute_value=\"research\"\n)\n\ndf = dp.convert_to_df(results)\ndf.to_csv(\"research_samples.csv\", index=False)\nprint(\"Data exported to research_samples.csv\")\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the User Guide for more detailed examples</li> <li>Check the API Reference for complete documentation</li> <li>Learn about Authentication in detail</li> <li>Review Data Processing capabilities</li> </ul>"},{"location":"user-guide/authentication/","title":"Authentication","text":"<p>BioEPIC Skills provides a robust authentication system for accessing protected API endpoints.</p>"},{"location":"user-guide/authentication/#overview","title":"Overview","text":"<p>The <code>BioEPICAuth</code> class handles authentication with the API, supporting both client credentials and username/password authentication methods.</p>"},{"location":"user-guide/authentication/#authentication-methods","title":"Authentication Methods","text":""},{"location":"user-guide/authentication/#client-credentials","title":"Client Credentials","text":"<p>Recommended for server-to-server authentication:</p> <pre><code>from bioepic_skills.auth import BioEPICAuth\n\nauth = BioEPICAuth(\n    client_id=\"your_client_id\",\n    client_secret=\"your_client_secret\",\n    env=\"prod\"\n)\n</code></pre>"},{"location":"user-guide/authentication/#username-and-password","title":"Username and Password","text":"<p>For user-based authentication:</p> <pre><code>auth = BioEPICAuth(\n    username=\"your_username\",\n    password=\"your_password\",\n    env=\"prod\"\n)\n</code></pre>"},{"location":"user-guide/authentication/#using-environment-variables","title":"Using Environment Variables","text":"<p>Best Practice: Store credentials in environment variables:</p>"},{"location":"user-guide/authentication/#setup-env-file","title":"Setup .env File","text":"<p>Create a <code>.env</code> file:</p> <pre><code># .env\nENV=prod\nCLIENT_ID=your_client_id_here\nCLIENT_SECRET=your_client_secret_here\n</code></pre>"},{"location":"user-guide/authentication/#load-and-use","title":"Load and Use","text":"<pre><code>import os\nfrom dotenv import load_dotenv\nfrom bioepic_skills.auth import BioEPICAuth\n\n# Load environment variables\nload_dotenv()\n\n# Initialize with environment variables\nauth = BioEPICAuth(\n    client_id=os.getenv(\"CLIENT_ID\"),\n    client_secret=os.getenv(\"CLIENT_SECRET\"),\n    env=os.getenv(\"ENV\", \"prod\")\n)\n</code></pre>"},{"location":"user-guide/authentication/#token-management","title":"Token Management","text":"<p>The authentication system automatically manages tokens:</p>"},{"location":"user-guide/authentication/#getting-a-token","title":"Getting a Token","text":"<pre><code># Get or refresh token automatically\ntoken = auth.get_token()\nprint(f\"Token: {token[:20]}...\")  # Show first 20 chars\n</code></pre>"},{"location":"user-guide/authentication/#check-credentials","title":"Check Credentials","text":"<pre><code>if auth.has_credentials():\n    print(\"Credentials are configured\")\n    token = auth.get_token()\nelse:\n    print(\"No credentials found\")\n</code></pre>"},{"location":"user-guide/authentication/#token-expiry","title":"Token Expiry","text":"<p>Tokens are automatically refreshed when needed:</p> <ul> <li>Tokens are cached until they expire</li> <li>A 5-minute buffer before expiry triggers automatic refresh</li> <li>You don't need to manually manage token lifecycle</li> </ul>"},{"location":"user-guide/authentication/#using-the-requires_auth-decorator","title":"Using the @requires_auth Decorator","text":"<p>Protect methods that require authentication:</p> <pre><code>from bioepic_skills.decorators import requires_auth\nfrom bioepic_skills.auth import BioEPICAuth\n\nclass MyAPIClient:\n    def __init__(self, auth: BioEPICAuth):\n        self.auth = auth\n\n    @requires_auth\n    def protected_method(self):\n        \"\"\"This method requires authentication\"\"\"\n        token = self.auth.get_token()\n        # Use token in API call...\n        pass\n</code></pre>"},{"location":"user-guide/authentication/#error-handling","title":"Error Handling","text":""},{"location":"user-guide/authentication/#authentication-errors","title":"Authentication Errors","text":"<pre><code>from bioepic_skills.decorators import AuthenticationError\n\ntry:\n    auth = BioEPICAuth(\n        client_id=os.getenv(\"CLIENT_ID\"),\n        client_secret=os.getenv(\"CLIENT_SECRET\")\n    )\n\n    if not auth.has_credentials():\n        raise AuthenticationError(\"No credentials provided\")\n\n    token = auth.get_token()\n\nexcept AuthenticationError as e:\n    print(f\"Authentication failed: {e}\")\nexcept RuntimeError as e:\n    print(f\"Token refresh failed: {e}\")\n</code></pre>"},{"location":"user-guide/authentication/#complete-example","title":"Complete Example","text":"<pre><code>import os\nimport logging\nfrom dotenv import load_dotenv\nfrom bioepic_skills.auth import BioEPICAuth\nfrom bioepic_skills.api_search import APISearch\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Load environment variables\nload_dotenv()\n\ndef main():\n    # Initialize authentication\n    auth = BioEPICAuth(\n        client_id=os.getenv(\"CLIENT_ID\"),\n        client_secret=os.getenv(\"CLIENT_SECRET\"),\n        env=os.getenv(\"ENV\", \"prod\")\n    )\n\n    # Verify credentials\n    if not auth.has_credentials():\n        logger.error(\"No credentials found. Check your .env file.\")\n        return\n\n    logger.info(\"Authentication initialized\")\n\n    # Get token\n    try:\n        token = auth.get_token()\n        logger.info(\"Token acquired successfully\")\n    except RuntimeError as e:\n        logger.error(f\"Failed to get token: {e}\")\n        return\n\n    # Use with API client\n    api_client = APISearch(collection_name=\"samples\")\n    # Make authenticated requests...\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"user-guide/authentication/#security-best-practices","title":"Security Best Practices","text":""},{"location":"user-guide/authentication/#1-never-hardcode-credentials","title":"1. Never Hardcode Credentials","text":"<p>\u274c Don't do this:</p> <pre><code>auth = BioEPICAuth(\n    client_id=\"abc123\",  # Hardcoded!\n    client_secret=\"secret456\"  # Hardcoded!\n)\n</code></pre> <p>\u2705 Do this:</p> <pre><code>auth = BioEPICAuth(\n    client_id=os.getenv(\"CLIENT_ID\"),\n    client_secret=os.getenv(\"CLIENT_SECRET\")\n)\n</code></pre>"},{"location":"user-guide/authentication/#2-keep-env-files-secure","title":"2. Keep .env Files Secure","text":"<ul> <li>Add <code>.env</code> to <code>.gitignore</code></li> <li>Never commit <code>.env</code> files to version control</li> <li>Use <code>.env.example</code> as a template</li> </ul>"},{"location":"user-guide/authentication/#3-use-different-credentials-for-different-environments","title":"3. Use Different Credentials for Different Environments","text":"<pre><code># Development\nauth_dev = BioEPICAuth(\n    client_id=os.getenv(\"DEV_CLIENT_ID\"),\n    client_secret=os.getenv(\"DEV_CLIENT_SECRET\"),\n    env=\"dev\"\n)\n\n# Production\nauth_prod = BioEPICAuth(\n    client_id=os.getenv(\"PROD_CLIENT_ID\"),\n    client_secret=os.getenv(\"PROD_CLIENT_SECRET\"),\n    env=\"prod\"\n)\n</code></pre>"},{"location":"user-guide/authentication/#4-rotate-credentials-regularly","title":"4. Rotate Credentials Regularly","text":"<p>Establish a process for regular credential rotation, especially for production environments.</p>"},{"location":"user-guide/authentication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/authentication/#no-credentials-found-error","title":"\"No credentials found\" Error","text":"<p>Check that: 1. <code>.env</code> file exists in your project root 2. Environment variables are properly set 3. You're calling <code>load_dotenv()</code> before accessing credentials</p>"},{"location":"user-guide/authentication/#token-refresh-failures","title":"Token Refresh Failures","text":"<p>If token refresh fails: 1. Verify your credentials are still valid 2. Check network connectivity to the auth endpoint 3. Ensure the auth endpoint URL is correct in <code>api_base.py</code></p>"},{"location":"user-guide/authentication/#invalid-credentials","title":"Invalid Credentials","text":"<p>If you receive authentication errors: 1. Verify credentials in your account dashboard 2. Ensure you're using the correct environment (prod vs dev) 3. Check that credentials haven't expired</p>"},{"location":"user-guide/authentication/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see:</p> <ul> <li>BioEPICAuth API</li> <li>Decorators API</li> </ul>"},{"location":"user-guide/data-processing/","title":"Data Processing","text":"<p>The <code>DataProcessing</code> class provides utilities for transforming and analyzing data retrieved from APIs.</p>"},{"location":"user-guide/data-processing/#overview","title":"Overview","text":"<p>Data processing capabilities include:</p> <ul> <li>Converting data to pandas DataFrames</li> <li>Building MongoDB-style filters</li> <li>Merging and transforming data</li> <li>Extracting specific fields</li> <li>Chunking large datasets</li> </ul>"},{"location":"user-guide/data-processing/#converting-to-dataframes","title":"Converting to DataFrames","text":""},{"location":"user-guide/data-processing/#basic-conversion","title":"Basic Conversion","text":"<pre><code>from bioepic_skills.data_processing import DataProcessing\n\ndp = DataProcessing()\n\n# Convert list of dictionaries to DataFrame\nrecords = [\n    {\"id\": \"1\", \"name\": \"Sample 1\", \"value\": 10},\n    {\"id\": \"2\", \"name\": \"Sample 2\", \"value\": 20},\n]\n\ndf = dp.convert_to_df(records)\nprint(df)\n</code></pre> <p>Output: <pre><code>  id      name  value\n0  1  Sample 1     10\n1  2  Sample 2     20\n</code></pre></p>"},{"location":"user-guide/data-processing/#working-with-api-results","title":"Working with API Results","text":"<pre><code>from bioepic_skills.api_search import APISearch\n\napi_client = APISearch(collection_name=\"samples\")\nrecords = api_client.get_records(max_page_size=100)\n\n# Convert to DataFrame for analysis\ndf = dp.convert_to_df(records)\n\n# Now use pandas operations\nprint(df.describe())\nprint(df.info())\n</code></pre>"},{"location":"user-guide/data-processing/#building-filters","title":"Building Filters","text":""},{"location":"user-guide/data-processing/#regex-filters-partial-match","title":"Regex Filters (Partial Match)","text":"<pre><code># Build a filter for partial matches\nfilter_dict = dp.build_filter(\n    {\n        \"name\": \"sample\",\n        \"type\": \"biological\"\n    },\n    exact_match=False\n)\n\n# Use with API\napi_client = APISearch(collection_name=\"samples\")\nresults = api_client.get_record_by_filter(filter_dict)\n</code></pre> <p>The filter will match records where: - <code>name</code> contains \"sample\" (case-insensitive) - <code>type</code> contains \"biological\" (case-insensitive)</p>"},{"location":"user-guide/data-processing/#exact-match-filters","title":"Exact Match Filters","text":"<pre><code># Build a filter for exact matches\nfilter_dict = dp.build_filter(\n    {\n        \"id\": \"sample-12345\",\n        \"status\": \"active\"\n    },\n    exact_match=True\n)\n</code></pre>"},{"location":"user-guide/data-processing/#special-characters-in-filters","title":"Special Characters in Filters","text":"<p>Special characters are automatically escaped:</p> <pre><code># This works correctly with special characters\nfilter_dict = dp.build_filter(\n    {\n        \"title\": \"GC-MS (2009)\",  # Parentheses will be escaped\n    },\n    exact_match=False\n)\n</code></pre>"},{"location":"user-guide/data-processing/#extracting-fields","title":"Extracting Fields","text":""},{"location":"user-guide/data-processing/#extract-single-field","title":"Extract Single Field","text":"<pre><code># Extract IDs from records\nids = dp.extract_field(records, \"id\")\nprint(f\"Found {len(ids)} IDs: {ids[:5]}\")\n\n# Extract names\nnames = dp.extract_field(records, \"name\")\n</code></pre>"},{"location":"user-guide/data-processing/#extract-multiple-fields","title":"Extract Multiple Fields","text":"<pre><code># Extract different fields\nids = dp.extract_field(records, \"id\")\nnames = dp.extract_field(records, \"name\")\nvalues = dp.extract_field(records, \"value\")\n\n# Create a new DataFrame with selected fields\nimport pandas as pd\ndf_selected = pd.DataFrame({\n    \"id\": ids,\n    \"name\": names,\n    \"value\": values\n})\n</code></pre>"},{"location":"user-guide/data-processing/#merging-data","title":"Merging Data","text":""},{"location":"user-guide/data-processing/#simple-merge","title":"Simple Merge","text":"<p>Merge two DataFrames on a common column:</p> <pre><code># Two DataFrames with common 'id' column\ndf1 = dp.convert_to_df(samples)\ndf2 = dp.convert_to_df(metadata)\n\n# Merge on 'id'\nmerged = dp.merge_dataframes(\"id\", df1, df2)\n</code></pre>"},{"location":"user-guide/data-processing/#advanced-merge","title":"Advanced Merge","text":"<p>Merge with different column names:</p> <pre><code># df1 has 'sample_id', df2 has 'id'\nmerged = dp.merge_df(\n    df1=samples_df,\n    df2=metadata_df,\n    key1=\"sample_id\",\n    key2=\"id\"\n)\n</code></pre> <p>This method also: - Automatically handles list-type columns by exploding them - Removes duplicate rows - Performs inner join by default</p>"},{"location":"user-guide/data-processing/#list-operations","title":"List Operations","text":""},{"location":"user-guide/data-processing/#split-into-chunks","title":"Split into Chunks","text":"<pre><code># Split a large list into smaller chunks\nlarge_list = list(range(250))\nchunks = dp.split_list(large_list, chunk_size=100)\n\nprint(f\"Split into {len(chunks)} chunks\")\n# Output: Split into 3 chunks\n\n# Process each chunk\nfor i, chunk in enumerate(chunks):\n    print(f\"Chunk {i+1}: {len(chunk)} items\")\n</code></pre> <p>Use case - batch processing:</p> <pre><code># Get a large list of IDs\nall_ids = dp.extract_field(records, \"id\")\n\n# Process in batches of 50\nfor batch in dp.split_list(all_ids, chunk_size=50):\n    # Process this batch\n    batch_data = api_client.get_batch_records(batch)\n    # ... process batch_data\n</code></pre>"},{"location":"user-guide/data-processing/#renaming-columns","title":"Renaming Columns","text":"<pre><code># Original DataFrame\ndf = dp.convert_to_df(records)\nprint(df.columns)\n# Output: Index(['id', 'name', 'type'], dtype='object')\n\n# Rename all columns\nnew_names = [\"ID\", \"Sample Name\", \"Sample Type\"]\ndf_renamed = dp.rename_columns(df, new_names)\nprint(df_renamed.columns)\n# Output: Index(['ID', 'Sample Name', 'Sample Type'], dtype='object')\n</code></pre> <p>Column Count Must Match</p> <p>The number of new column names must exactly match the number of columns in the DataFrame.</p>"},{"location":"user-guide/data-processing/#complete-workflow-example","title":"Complete Workflow Example","text":""},{"location":"user-guide/data-processing/#data-retrieval-and-processing","title":"Data Retrieval and Processing","text":"<pre><code>from bioepic_skills.api_search import APISearch\nfrom bioepic_skills.data_processing import DataProcessing\nimport pandas as pd\n\n# Initialize\napi_client = APISearch(collection_name=\"samples\")\ndp = DataProcessing()\n\n# Step 1: Retrieve data with filter\nfilter_dict = dp.build_filter(\n    {\"category\": \"research\", \"status\": \"active\"},\n    exact_match=False\n)\n\nrecords = api_client.get_record_by_filter(\n    filter=filter_dict,\n    all_pages=True\n)\n\nprint(f\"Retrieved {len(records)} records\")\n\n# Step 2: Convert to DataFrame\ndf = dp.convert_to_df(records)\n\n# Step 3: Extract and process specific fields\nsample_ids = dp.extract_field(records, \"id\")\nprint(f\"Sample IDs: {len(sample_ids)}\")\n\n# Step 4: Get related data\nrelated_records = []\nfor chunk in dp.split_list(sample_ids, chunk_size=50):\n    # Get related data for this chunk\n    chunk_filter = dp.build_filter(\n        {\"sample_id\": chunk[0]},  # Simplified example\n        exact_match=True\n    )\n    batch = api_client.get_record_by_filter(chunk_filter)\n    related_records.extend(batch)\n\n# Step 5: Merge datasets\nrelated_df = dp.convert_to_df(related_records)\nfinal_df = dp.merge_df(\n    df1=df,\n    df2=related_df,\n    key1=\"id\",\n    key2=\"sample_id\"\n)\n\n# Step 6: Process and export\nfinal_df[\"date\"] = pd.to_datetime(final_df[\"date\"])\nfinal_df = final_df.sort_values(\"date\")\nfinal_df.to_csv(\"research_samples_processed.csv\", index=False)\n\nprint(f\"Exported {len(final_df)} processed records\")\n</code></pre>"},{"location":"user-guide/data-processing/#batch-processing-large-datasets","title":"Batch Processing Large Datasets","text":"<pre><code>def process_large_dataset(api_client, dp, total_records):\n    \"\"\"Process a large dataset in manageable chunks\"\"\"\n    chunk_size = 100\n    all_results = []\n\n    for offset in range(0, total_records, chunk_size):\n        # Get chunk\n        records = api_client.get_records(\n            max_page_size=chunk_size,\n            # Implement pagination based on your API\n        )\n\n        # Process chunk\n        df_chunk = dp.convert_to_df(records)\n\n        # Filter and transform\n        df_chunk = df_chunk[df_chunk[\"status\"] == \"active\"]\n        df_chunk[\"processed\"] = True\n\n        # Store results\n        all_results.append(df_chunk)\n\n        print(f\"Processed {offset + len(records)}/{total_records}\")\n\n    # Combine all chunks\n    final_df = pd.concat(all_results, ignore_index=True)\n    return final_df\n</code></pre>"},{"location":"user-guide/data-processing/#performance-tips","title":"Performance Tips","text":""},{"location":"user-guide/data-processing/#1-use-chunking-for-large-datasets","title":"1. Use Chunking for Large Datasets","text":"<pre><code># Instead of loading everything at once\nbig_list = range(10000)\nfor chunk in dp.split_list(big_list, chunk_size=100):\n    # Process manageable chunks\n    pass\n</code></pre>"},{"location":"user-guide/data-processing/#2-select-only-needed-fields","title":"2. Select Only Needed Fields","text":"<pre><code># Get only required fields from API\nrecords = api_client.get_records(\n    max_page_size=100,\n    fields=\"id,name,date\"  # Only get what you need\n)\n</code></pre>"},{"location":"user-guide/data-processing/#3-filter-early","title":"3. Filter Early","text":"<pre><code># Filter at the API level, not in pandas\nfilter_dict = dp.build_filter({\"status\": \"active\"})\nrecords = api_client.get_record_by_filter(filter_dict)\n\n# Better than:\n# all_records = api_client.get_records()\n# df = dp.convert_to_df(all_records)\n# df = df[df[\"status\"] == \"active\"]  # Slower!\n</code></pre>"},{"location":"user-guide/data-processing/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see:</p> <ul> <li>DataProcessing API</li> </ul>"},{"location":"user-guide/usage/","title":"Usage Guide","text":"<p>This guide covers common usage patterns and best practices for BioEPIC Skills.</p>"},{"location":"user-guide/usage/#api-client-initialization","title":"API Client Initialization","text":""},{"location":"user-guide/usage/#basic-initialization","title":"Basic Initialization","text":"<pre><code>from bioepic_skills.api_search import APISearch\n\n# Initialize with a collection name\napi_client = APISearch(collection_name=\"samples\")\n</code></pre>"},{"location":"user-guide/usage/#environment-configuration","title":"Environment Configuration","text":"<p>You can specify different environments (production or development):</p> <pre><code># Use production environment (default)\napi_client = APISearch(collection_name=\"samples\", env=\"prod\")\n\n# Use development environment\napi_client = APISearch(collection_name=\"samples\", env=\"dev\")\n</code></pre>"},{"location":"user-guide/usage/#querying-data","title":"Querying Data","text":""},{"location":"user-guide/usage/#get-records","title":"Get Records","text":"<p>Retrieve records from a collection:</p> <pre><code># Get first 100 records\nrecords = api_client.get_records(max_page_size=100)\n\n# Get all records (with pagination)\nall_records = api_client.get_records(max_page_size=100, all_pages=True)\n\n# Get specific fields only\nrecords = api_client.get_records(\n    max_page_size=50,\n    fields=\"id,name,description\"\n)\n</code></pre>"},{"location":"user-guide/usage/#filter-records","title":"Filter Records","text":"<p>Use MongoDB-style filters:</p> <pre><code># Simple filter\nfilter_str = '{\"type\": \"sample\"}'\nrecords = api_client.get_record_by_filter(filter_str)\n\n# Complex filter with multiple conditions\nfilter_str = '{\"type\": \"sample\", \"status\": \"active\"}'\nrecords = api_client.get_record_by_filter(\n    filter=filter_str,\n    max_page_size=50,\n    all_pages=True\n)\n</code></pre>"},{"location":"user-guide/usage/#search-by-attribute","title":"Search by Attribute","text":"<p>Search for records matching specific attributes:</p> <pre><code># Partial match (default)\nresults = api_client.get_record_by_attribute(\n    attribute_name=\"name\",\n    attribute_value=\"test\",\n    exact_match=False\n)\n\n# Exact match\nresults = api_client.get_record_by_attribute(\n    attribute_name=\"id\",\n    attribute_value=\"sample-12345\",\n    exact_match=True\n)\n</code></pre>"},{"location":"user-guide/usage/#get-single-record","title":"Get Single Record","text":"<p>Retrieve a specific record by ID:</p> <pre><code>record = api_client.get_record_by_id(\"sample-12345\")\nprint(f\"Record name: {record['name']}\")\n</code></pre>"},{"location":"user-guide/usage/#working-with-results","title":"Working with Results","text":""},{"location":"user-guide/usage/#convert-to-dataframe","title":"Convert to DataFrame","text":"<pre><code>from bioepic_skills.data_processing import DataProcessing\n\ndp = DataProcessing()\n\n# Convert list of dicts to pandas DataFrame\ndf = dp.convert_to_df(records)\n\n# View first few rows\nprint(df.head())\n\n# Get summary statistics\nprint(df.describe())\n</code></pre>"},{"location":"user-guide/usage/#extract-specific-fields","title":"Extract Specific Fields","text":"<pre><code># Extract a single field from all records\nids = dp.extract_field(records, \"id\")\nnames = dp.extract_field(records, \"name\")\n\nprint(f\"Found {len(ids)} IDs\")\n</code></pre>"},{"location":"user-guide/usage/#process-large-datasets","title":"Process Large Datasets","text":"<pre><code># Split large lists into manageable chunks\nlarge_id_list = [...]  # Your list of IDs\nchunks = dp.split_list(large_id_list, chunk_size=100)\n\n# Process each chunk\nfor i, chunk in enumerate(chunks):\n    print(f\"Processing chunk {i+1}/{len(chunks)}\")\n    # Process chunk...\n</code></pre>"},{"location":"user-guide/usage/#building-filters","title":"Building Filters","text":""},{"location":"user-guide/usage/#simple-filters","title":"Simple Filters","text":"<pre><code># Build a regex-based filter\nfilter_dict = dp.build_filter(\n    {\"name\": \"sample\", \"type\": \"biological\"},\n    exact_match=False\n)\n\nresults = api_client.get_record_by_filter(filter_dict)\n</code></pre>"},{"location":"user-guide/usage/#exact-match-filters","title":"Exact Match Filters","text":"<pre><code># Build an exact match filter\nfilter_dict = dp.build_filter(\n    {\"id\": \"sample-12345\", \"status\": \"active\"},\n    exact_match=True\n)\n</code></pre>"},{"location":"user-guide/usage/#data-transformation","title":"Data Transformation","text":""},{"location":"user-guide/usage/#merge-dataframes","title":"Merge DataFrames","text":"<pre><code># Simple merge on a common column\nmerged_df = dp.merge_dataframes(\"id\", df1, df2)\n\n# Advanced merge with different keys\nmerged_df = dp.merge_df(\n    df1=samples_df,\n    df2=metadata_df,\n    key1=\"sample_id\",\n    key2=\"id\"\n)\n</code></pre>"},{"location":"user-guide/usage/#rename-columns","title":"Rename Columns","text":"<pre><code># Rename all columns\nnew_names = [\"ID\", \"Name\", \"Description\"]\ndf_renamed = dp.rename_columns(df, new_names)\n</code></pre>"},{"location":"user-guide/usage/#error-handling","title":"Error Handling","text":"<p>Always include proper error handling:</p> <pre><code>try:\n    records = api_client.get_records(max_page_size=100)\n    df = dp.convert_to_df(records)\nexcept RuntimeError as e:\n    print(f\"API request failed: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"user-guide/usage/#logging-and-debugging","title":"Logging and Debugging","text":""},{"location":"user-guide/usage/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code>import logging\n\n# Set logging level\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Now your API calls will show detailed debug information\n</code></pre>"},{"location":"user-guide/usage/#custom-logger","title":"Custom Logger","text":"<pre><code>import logging\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\n# Use in your code\nlogger.info(\"Starting data retrieval...\")\nrecords = api_client.get_records(max_page_size=100)\nlogger.info(f\"Retrieved {len(records)} records\")\n</code></pre>"},{"location":"user-guide/usage/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/usage/#1-use-environment-variables","title":"1. Use Environment Variables","text":"<p>Always store credentials in environment variables:</p> <pre><code>import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient_id = os.getenv(\"CLIENT_ID\")\nclient_secret = os.getenv(\"CLIENT_SECRET\")\n</code></pre>"},{"location":"user-guide/usage/#2-handle-pagination-efficiently","title":"2. Handle Pagination Efficiently","text":"<p>For large datasets:</p> <pre><code># Process data in chunks instead of loading all at once\ndef process_in_batches():\n    page_size = 100\n    records = api_client.get_records(max_page_size=page_size)\n\n    while records:\n        # Process current batch\n        df = dp.convert_to_df(records)\n        # ... do something with df\n\n        # Get next batch\n        # (Implementation depends on your API's pagination)\n        break  # Remove this and implement proper pagination\n</code></pre>"},{"location":"user-guide/usage/#3-validate-data","title":"3. Validate Data","text":"<p>Always validate your data:</p> <pre><code># Check for required fields\nrequired_fields = [\"id\", \"name\", \"type\"]\nif all(field in record for field in required_fields):\n    # Process record\n    pass\nelse:\n    print(\"Missing required fields\")\n</code></pre>"},{"location":"user-guide/usage/#4-cache-results","title":"4. Cache Results","text":"<p>For expensive queries:</p> <pre><code>import pickle\n\n# Save results\nwith open(\"cached_results.pkl\", \"wb\") as f:\n    pickle.dump(records, f)\n\n# Load cached results\nwith open(\"cached_results.pkl\", \"rb\") as f:\n    records = pickle.load(f)\n</code></pre>"},{"location":"user-guide/usage/#example-workflows","title":"Example Workflows","text":""},{"location":"user-guide/usage/#complete-data-retrieval-and-analysis","title":"Complete Data Retrieval and Analysis","text":"<pre><code>from bioepic_skills.api_search import APISearch\nfrom bioepic_skills.data_processing import DataProcessing\nimport pandas as pd\n\n# Initialize\napi_client = APISearch(collection_name=\"samples\")\ndp = DataProcessing()\n\n# Retrieve data\nrecords = api_client.get_record_by_attribute(\n    attribute_name=\"category\",\n    attribute_value=\"research\",\n    all_pages=True\n)\n\n# Convert and process\ndf = dp.convert_to_df(records)\n\n# Filter and transform\ndf_filtered = df[df[\"status\"] == \"active\"]\ndf_filtered[\"date\"] = pd.to_datetime(df_filtered[\"date\"])\n\n# Export results\ndf_filtered.to_csv(\"research_samples.csv\", index=False)\nprint(f\"Exported {len(df_filtered)} records\")\n</code></pre>"},{"location":"user-guide/usage/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Authentication</li> <li>Explore Data Processing in depth</li> <li>Check the API Reference</li> </ul>"}]}